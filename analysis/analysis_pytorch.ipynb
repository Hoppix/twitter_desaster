{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a classifier pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDisasterClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(TweetDisasterClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        \n",
    "        self.fc_last = nn.Linear(hidden_sizes[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            out = hidden_layer(out)\n",
    "            out = self.relu(out)\n",
    "        \n",
    "        out = self.fc_last(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 30 * 300 # dimensionality for maximum of 30 words\n",
    "hidden_size = [128, 264, 128]\n",
    "num_classes = 2\n",
    "\n",
    "model = TweetDisasterClassifier(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df = df.sample(frac=1)\n",
    "df['tokenized_text'] = df['text'].apply(tokenizer)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>809</td>\n",
       "      <td>battle</td>\n",
       "      <td>Baton Rouge, LA</td>\n",
       "      <td>#DU19 who gon get in this rap battle with me</td>\n",
       "      <td>0</td>\n",
       "      <td>[#du19, who, gon, get, in, this, rap, battle, ...</td>\n",
       "      <td>[3000000, 74, 3000000, 43641, 3000000, 86, 300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>5025</td>\n",
       "      <td>eyewitness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interesting approach but doesn't replace Eyewi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[interesting, approach, but, doesn, ', t, repl...</td>\n",
       "      <td>[939, 3000000, 1399, 3000000, 42, 3000000, 234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>2459</td>\n",
       "      <td>collided</td>\n",
       "      <td>Peterborough, On</td>\n",
       "      <td>#Newswatch: 2 vehicles collided at Lock and La...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#newswatch, 2, vehicles, collided, at, lock, ...</td>\n",
       "      <td>[3000000, 80, 3000000, 2951, 3000000, 43975, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>8060</td>\n",
       "      <td>rescue</td>\n",
       "      <td>Trinidad &amp; Tobago</td>\n",
       "      <td>Policyholders object to Clico rescue plan http...</td>\n",
       "      <td>1</td>\n",
       "      <td>[policyholders, object, to, clico, rescue, pla...</td>\n",
       "      <td>[66948, 3000000, 2355, 3000000, 4, 3000000, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>63</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOOOO PUMPED FOR ABLAZE ???? @southridgelife</td>\n",
       "      <td>0</td>\n",
       "      <td>[soooo, pumped, for, ablaze, ?, ?, ?, ?, @sout...</td>\n",
       "      <td>[15809, 3000000, 16846, 3000000, 11, 3000000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>6441</td>\n",
       "      <td>injured</td>\n",
       "      <td>MD</td>\n",
       "      <td>And you wonder why he's injured every year htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[and, you, wonder, why, he, ', s, injured, eve...</td>\n",
       "      <td>[3, 3000000, 18, 3000000, 1817, 3000000, 297, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>5037</td>\n",
       "      <td>eyewitness</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Read an eyewitness account from #Hiroshima fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>[read, an, eyewitness, account, from, #hiroshi...</td>\n",
       "      <td>[301, 3000000, 39, 3000000, 48864, 3000000, 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>8980</td>\n",
       "      <td>storm</td>\n",
       "      <td>#PhanTrash</td>\n",
       "      <td>The sky's clear the storm has passed but it's ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, sky, ', s, clear, the, storm, has, passe...</td>\n",
       "      <td>[2, 3000000, 4027, 3000000, 55, 3000000, 269, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>2297</td>\n",
       "      <td>cliff%20fall</td>\n",
       "      <td>DRAW A CIRCLE THAT'S THE EARTH</td>\n",
       "      <td>*Jumps off of a cliff while drinking tea*\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>[*jumps, off, of, a, cliff, while, drinking, t...</td>\n",
       "      <td>[3000000, 184, 3000000, 5, 3000000, 6, 3000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>3742</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, eye, 9, a, space, battle, occurred, at...</td>\n",
       "      <td>[536, 3000000, 1527, 3000000, 303, 3000000, 6,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       keyword                        location  \\\n",
       "560    809        battle                 Baton Rouge, LA   \n",
       "3515  5025    eyewitness                             NaN   \n",
       "1704  2459      collided                Peterborough, On   \n",
       "5649  8060        rescue               Trinidad & Tobago   \n",
       "43      63        ablaze                             NaN   \n",
       "...    ...           ...                             ...   \n",
       "4530  6441       injured                              MD   \n",
       "3523  5037    eyewitness                     Philippines   \n",
       "6287  8980         storm                      #PhanTrash   \n",
       "1590  2297  cliff%20fall  DRAW A CIRCLE THAT'S THE EARTH   \n",
       "2607  3742     destroyed                             USA   \n",
       "\n",
       "                                                   text  target  \\\n",
       "560        #DU19 who gon get in this rap battle with me       0   \n",
       "3515  Interesting approach but doesn't replace Eyewi...       1   \n",
       "1704  #Newswatch: 2 vehicles collided at Lock and La...       1   \n",
       "5649  Policyholders object to Clico rescue plan http...       1   \n",
       "43         SOOOO PUMPED FOR ABLAZE ???? @southridgelife       0   \n",
       "...                                                 ...     ...   \n",
       "4530  And you wonder why he's injured every year htt...       0   \n",
       "3523  Read an eyewitness account from #Hiroshima fro...       1   \n",
       "6287  The sky's clear the storm has passed but it's ...       0   \n",
       "1590  *Jumps off of a cliff while drinking tea*\\n\\nT...       0   \n",
       "2607  Black Eye 9: A space battle occurred at Star O...       0   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "560   [#du19, who, gon, get, in, this, rap, battle, ...   \n",
       "3515  [interesting, approach, but, doesn, ', t, repl...   \n",
       "1704  [#newswatch, 2, vehicles, collided, at, lock, ...   \n",
       "5649  [policyholders, object, to, clico, rescue, pla...   \n",
       "43    [soooo, pumped, for, ablaze, ?, ?, ?, ?, @sout...   \n",
       "...                                                 ...   \n",
       "4530  [and, you, wonder, why, he, ', s, injured, eve...   \n",
       "3523  [read, an, eyewitness, account, from, #hiroshi...   \n",
       "6287  [the, sky, ', s, clear, the, storm, has, passe...   \n",
       "1590  [*jumps, off, of, a, cliff, while, drinking, t...   \n",
       "2607  [black, eye, 9, a, space, battle, occurred, at...   \n",
       "\n",
       "                                             embeddings  \n",
       "560   [3000000, 74, 3000000, 43641, 3000000, 86, 300...  \n",
       "3515  [939, 3000000, 1399, 3000000, 42, 3000000, 234...  \n",
       "1704  [3000000, 80, 3000000, 2951, 3000000, 43975, 3...  \n",
       "5649  [66948, 3000000, 2355, 3000000, 4, 3000000, 30...  \n",
       "43    [15809, 3000000, 16846, 3000000, 11, 3000000, ...  \n",
       "...                                                 ...  \n",
       "4530  [3, 3000000, 18, 3000000, 1817, 3000000, 297, ...  \n",
       "3523  [301, 3000000, 39, 3000000, 48864, 3000000, 90...  \n",
       "6287  [2, 3000000, 4027, 3000000, 55, 3000000, 269, ...  \n",
       "1590  [3000000, 184, 3000000, 5, 3000000, 6, 3000000...  \n",
       "2607  [536, 3000000, 1527, 3000000, 303, 3000000, 6,...  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = GloVe(name='840B', dim=300)\n",
    "\n",
    "def embed(tokens):\n",
    "    embeds = []\n",
    "    for token in tokens:\n",
    "        if token in glove.stoi:\n",
    "            embeds.append(glove.stoi[token])\n",
    "        embeds.append(3000000) # maybe change this we ignore alot of unknowns here\n",
    "    \n",
    "    return embeds\n",
    "\n",
    "\n",
    "df[\"embeddings\"] = df[\"tokenized_text\"].apply(embed)\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Convert the data into PyTorch tensors\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(X_train)\n\u001b[1;32m      6\u001b[0m y_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(y_train)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Create a data loader\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Convert the data into PyTorch tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "# Create a data loader\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
